<script type="text/javascript">
        var gk_isXlsx = false;
        var gk_xlsxFileLookup = {};
        var gk_fileData = {};
        function filledCell(cell) {
          return cell !== '' && cell != null;
        }
        function loadFileData(filename) {
        if (gk_isXlsx && gk_xlsxFileLookup[filename]) {
            try {
                var workbook = XLSX.read(gk_fileData[filename], { type: 'base64' });
                var firstSheetName = workbook.SheetNames[0];
                var worksheet = workbook.Sheets[firstSheetName];

                // Convert sheet to JSON to filter blank rows
                var jsonData = XLSX.utils.sheet_to_json(worksheet, { header: 1, blankrows: false, defval: '' });
                // Filter out blank rows (rows where all cells are empty, null, or undefined)
                var filteredData = jsonData.filter(row => row.some(filledCell));

                // Heuristic to find the header row by ignoring rows with fewer filled cells than the next row
                var headerRowIndex = filteredData.findIndex((row, index) =>
                  row.filter(filledCell).length >= filteredData[index + 1]?.filter(filledCell).length
                );
                // Fallback
                if (headerRowIndex === -1 || headerRowIndex > 25) {
                  headerRowIndex = 0;
                }

                // Convert filtered JSON back to CSV
                var csv = XLSX.utils.aoa_to_sheet(filteredData.slice(headerRowIndex)); // Create a new sheet from filtered array of arrays
                csv = XLSX.utils.sheet_to_csv(csv, { header: 1 });
                return csv;
            } catch (e) {
                console.error(e);
                return "";
            }
        }
        return gk_fileData[filename] || "";
        }
        </script><!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Actividad 6 - Python Script</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            background-color: #f5f5f5;
        }
        h1 {
            color: #333;
            text-align: center;
        }
        .code-container {
            background-color: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
            max-width: 800px;
            margin: 0 auto;
        }
        pre {
            margin: 0;
        }
        code {
            font-size: 14px;
            line-height: 1.5;
        }
    </style>
</head>
<body>
    <h1>Actividad 6 - 2.2 Pruebas de raíz unitaria</h1>
    <div class="code-container">
        <pre><code class="language-python">
# -*- coding: utf-8 -*-
"""Actividad 6 - 2.2 Pruebas de raíz unitaria

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1omhzyjXwn8xGZbeLjxW8R-5q59CayTN-
"""

import pandas as pd
import numpy as np
from statsmodels.tsa.ar_model import AutoReg
from statsmodels.tsa.stattools import adfuller, kpss
from statsmodels.tsa.vector_ar.vecm import coint_johansen
from google.colab import files
import io

# Uploading the six Excel files
print("Please upload your six Excel files for MSFT, JNJ, and DAL (1-min and 3-min data).")
uploaded = files.upload()

# Initialize dictionary to store data
files = {
    'MSFT_1min': None, 'MSFT_3min': None,
    'JNJ_1min': None, 'JNJ_3min': None,
    'DAL_1min': None, 'DAL_3min': None
}

# Prompt for each uploaded file to classify it
file_mapping = {}
for filename in uploaded.keys():
    print(f"\nFor file: {filename}")
    stock = input("Which stock is this file for? (Enter 'MSFT', 'JNJ', or 'DAL'): ").strip().upper()
    while stock not in ['MSFT', 'JNJ', 'DAL']:
        print("Invalid input. Please enter 'MSFT', 'JNJ', or 'DAL'.")
        stock = input("Which stock is this file for? (Enter 'MSFT', 'JNJ', or 'DAL'): ").strip().upper()

    timeframe = input(f"For {stock}, is this 1-minute or 3-minute data? (Enter '1min' or '3min'): ").strip()
    while timeframe not in ['1min', '3min']:
        print("Invalid input. Please enter '1min' or '3min'.")
        timeframe = input(f"For {stock}, is this 1-minute or 3-minute data? (Enter '1min' or '3min'): ").strip()

    key = f"{stock}_{timeframe}"
    if key in files:
        files[key] = pd.read_excel(io.BytesIO(uploaded[filename]))
        print(f"Assigned {filename} to {key}")
    else:
        print(f"Error: Invalid combination for {filename}. Skipping.")

# Check if all files were assigned
for key, df in files.items():
    if df is None:
        print(f"Warning: No file assigned for {key}. Analysis may be incomplete.")

# Extracting 'Close' column from each dataset
close_data = {}
for key, df in files.items():
    if df is not None:
        close_data[key] = df['Close']
    else:
        print(f"Skipping 'Close' extraction for {key} due to missing data.")

# Fitting AR(1) model for each dataset
ar_models = {}
for key, data in close_data.items():
    ar_model = AutoReg(data, lags=1).fit()
    ar_models[key] = ar_model
    print(f"\nAR(1) Model for {key}:")
    print(ar_model.summary())

# Performing Unit Root Tests (ADF and KPSS)
def unit_root_tests(series, name):
    print(f"\nUnit Root Tests for {name}:")
    # ADF Test
    adf_result = adfuller(series, autolag='AIC')
    print("ADF Test:")
    print(f"  Test Statistic: {adf_result[0]:.4f}")
    print(f"  p-value: {adf_result[1]:.4f}")
    print(f"  Critical Values: {adf_result[4]}")
    # KPSS Test
    kpss_result = kpss(series, regression='c')
    print("\nKPSS Test:")
    print(f"  Test Statistic: {kpss_result[0]:.4f}")
    print(f"  p-value: {kpss_result[1]:.4f}")
    print(f"  Critical Values: {kpss_result[3]}")

# Run unit root tests for each 'Close' series
for key, data in close_data.items():
    unit_root_tests(data, key)

# Cointegration Analysis for 1-minute and 3-minute data separately
def cointegration_analysis(data_dict, timeframe):
    # Combine Close prices for the given timeframe
    combined = pd.DataFrame({
        'MSFT': data_dict.get(f'MSFT_{timeframe}'),
        'JNJ': data_dict.get(f'JNJ_{timeframe}'),
        'DAL': data_dict.get(f'DAL_{timeframe}')
    }).dropna()  # Drop NaN values for alignment
    if combined.empty:
        print(f"\nCointegration Analysis for {timeframe} data: Skipped due to missing or misaligned data.")
        return
    print(f"\nCointegration Analysis for {timeframe} data:")
    coint_result = coint_johansen(combined, det_order=0, k_ar_diff=1)
    print("Eigenvalues of the cointegration matrix:")
    print(coint_result.eig)
    print("\nTrace Statistics:")
    print(coint_result.lr1)
    print("\nCritical Values (90%, 95%, 99%):")
    print(coint_result.cvt)
    print("\nEigen Statistics:")
    print(coint_result.lr2)
    print("\nCritical Values (90%, 95%, 99%):")
    print(coint_result.cvm)

# Perform cointegration analysis for 1-minute and 3-minute data
cointegration_analysis(close_data, '1min')
cointegration_analysis(close_data, '3min')
        </code></pre>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>
        hljs.highlightAll();
    </script>
</body>
</html>